% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/NNLearnCV.R
\name{NNLearnCV}
\alias{NNLearnCV}
\title{Nearest Neighbors Learning Algorithm}
\usage{
NNLearnCV(X.mat, y.vec, max.neighbors = 30, fold.vec = NULL,
  n.folds = 5)
}
\arguments{
\item{X.mat}{a training data set}

\item{y.vec}{a training data set}

\item{max.neighbors=30}{The max number of neighbors to fin the best k
in nearest neighbors}

\item{fold.vec=NULL}{is a vector of fold ID numbers. If fold.vec is NULL
randomly assign fold IDs from 1 to n.folds}

\item{n.folds=5}{is the number of folds used to compute error}
}
\value{
returnList a list containing:
        X.mat - training data
        y.vec - training data
        train.loss.mat - matrice of loss values for each fold and number
          of neighbors
        validation.loss.mat - matrice of loss values for each fold and
           number of neighbors
        train.loss.vec - vector with max.neighbors elements: 
           mean loss over all folds
        validation.loss.vec - vector with max.neighbors elements: 
           mean loss over all folds
        selected.neighbors - number of neighbors selected by minimizing 
           the mean validation loss
        predict(testX.mat) - a function that takes a matrix of 
           inputs/features and returns a vector of predictions. 
           It should check the type/dimension of testX.mat and stop() 
           with an informative error message if there are any issues.
}
\description{
This is a learning algorithm that uses cross-validation 
  to select the number of neighbors that minimizes the mean
  validation loss
}
\examples{
   library(codungProject1)
   
   data(zip.train, package = "ElemStatLearn")
   X.mat<-zip.train[1:50,-1]
   y.vec<-zip.train[1:50, 1]
   max.neighbors <- 6
   n.folds <- 7
   fold.vec <- sample(rep(1:n.folds, l=nrow(X.mat)))
   
  returned <- NNLearnCV(X.mat, y.vec, max.neighbors, fold.vec, n.folds)

}
